# IbexRL: Online Learning for HVAC Control with Differentiable MPC

IbexRL is an advanced control algorithm designed for optimizing HVAC systems in building environments. It leverages a core agent built on Differentiable Model Predictive Control (dMPC), enabling it to learn and adapt its control strategy online.

The framework supports two primary operational paths:
1.  **Imitation Learning (IL) + Online Learning:** A two-stage process where the agent is first pre-trained to mimic a baseline controller and then refined through online reinforcement learning.
2.  **Online Learning Only:** A direct approach that uses pre-trained IL parameters to immediately begin the online learning phase.

---

## üèõÔ∏è Repository Structure

Here are the key files and directories in this project:

* `IbexAgent.py`: The core of the project. Contains the differentiable MPC agent logic.
* `online_learning_main.py`: The main script to execute the online reinforcement learning experiments. **This is the primary file you will run.**
* `online_learning2.py`: Contains the main simulation loop that interacts with the BOPTEST environment. **Modify this file to adapt to new environments.**
* `train_imit.py`: The script used to run the initial imitation learning phase from scratch.
* `Gnu-RL/`: This directory contains baseline data generated by the default BOPTEST controller, which is used for both imitation learning and as a source of disturbances during online learning.
* `imit_environment.yaml`: Conda environment file for imitation learning.
* `online_environment.yaml`: Conda environment file for online learning.

---

## ‚öôÔ∏è Setup and Installation

Before running any experiments, you must set up the appropriate Conda environment.

### 1. For Imitation Learning (Optional)

If you plan to run the imitation learning phase from scratch, create and activate the `rl-imit` environment:

```bash
# Create the environment from the .yaml file
conda env create -f imit_environment.yaml

# Activate the environment
conda activate rl-imit
